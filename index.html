<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chaitat Utintu</title>
  
  <meta name="author" content="Chaitat Utintu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Chaitat Utintu</name> </br>
                utintu.c@gmail.com
              </p>

              <p>
                I'm currently studying <a href="https://catalogue.surrey.ac.uk/2023-4/programme/PFA61-14">Artificial Intelligence MSc</a> 
                at the University of Surrey, where I've been working on the thesis related to <a href="https://sketchx.eecs.qmul.ac.uk">SketchX</a> research
                under the supervision of <a href="http://www.pinakinathc.me">Pinaki Chowdhury</a> and <a href="https://www.surrey.ac.uk/people/yi-zhe-song">Professor Yi-Zhe Song</a>.
              </p>

              <p>I'm also a machine learning engineer at <a href="https://www.linkedin.com/company/ai-and-robotics-ventures/">AI and Robotics Ventures (ARV)</a>, subsidiary of 
                <a href="https://www.linkedin.com/company/pttep">PTTEP</a>. 
              </p>
              <p>
                At ARV, I've worked on computer vision projects in several areas, including
                <a href="https://ieeexplore.ieee.org/document/9795616">autonomous offshore mission</a>,
                <a href="https://ebooks.iospress.nl/doi/10.3233/ATDE230049"> safety control measures</a>, etc.
                My other key responsibilities are project management, MLOps pipeline implementation and model optimization for resource-constrained platforms.
              </p>

              <p style="text-align:center">
                    
                <a href="https://th.linkedin.com/in/chaitat-utintu-6418601b2">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=b2srDwoAAAAJ&hl=en&oi=ao">Scholar</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/@CHAITron">YouTube</a> &nbsp/&nbsp
                <a href="https://www.skilllane.com/courses/Deep-Learning-and-Computer-Vision">SkillLane</a> &nbsp/&nbsp
                <a href="https://www.youtube.com/@CHAITron">Blog</a> 

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.png"><img style="width:80%;max-width:80%" alt="profile photo" src="images/profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <h2>News / Talks</h2>
            <ul>
                <li><b>July 2023</b>: My team, Fallen Angels, won <a href="https://scontent-lhr8-1.xx.fbcdn.net/v/t39.30808-6/358131333_1304847516932349_3979243005211970539_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=5f2048&_nc_ohc=M1UGo6iRzAIAX9YpX_B&_nc_ht=scontent-lhr8-1.xx&oh=00_AfB1RmvsS7A9XMirIOqaADuNWmO4LtHBgFpx1Ky2jLVDeg&oe=654417D4">
                  2nd place</a> on ARV Anti-drone Hack Hunter 2023 </li>
                <li><b>June 2023</b>: <a href="https://www.surrey.ac.uk/fees-and-funding/scholarships-and-bursaries/international-excellence-award-postgraduate-february-2024-2023">
                  The International Excellence Postgraduate scholarship</a> @ University of Surrey </li>
                <li><b>March 2023</b>: Guest Speaker on Generative AI @ NVIDIA GTC 2023 </li>
                <li><b>November 2022</b>: <a href="https://www.credly.com/badges/53c9076a-6cac-4cb8-a65b-0f6243eb3917/linked_in_profile?fbclid=IwAR1hAa0Mh6ZbAaaQu60L_vkmXxu2e_E5ceez6U8h-20yr7kXlTQ58qlDn90">
                  IBM Quantum Challenge Fall 2022 Achievement - Foundation</a> </li>
                <li><b>July 2022</b>: External Technical Committee @ RoboCup 2022 </li>
                <li><b>November 2021</b>: Machine Learning Guest Lecturer @ NIDA Thailand</li>
            </ul>
            <!--<h2>Research 	&#129302;</h2>-->



        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <p>Representative papers are <span class="highlight">highlighted</span>.</p>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/paper4.png" alt="" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ebooks.iospress.nl/doi/10.3233/ATDE230049">
                <papertitle>Hot Work Control Measures Using CNN-Based Object Detection and Projective Geometry for Industrial Surveillance Application</papertitle>
              </a>
              <br>
              <a href="https://th.linkedin.com/in/pakcheera-choppradit/en"> Pakcheera Choppradit</a>,
              <strong> Chaitat Utintu</strong>,
              <a href="https://th.linkedin.com/in/kasisdis-mahakijdechachai-a7b23b123"> Kasisdis Mahakijdechachai</a>,
              <a href="https://www.eg.mahidol.ac.th/egmu_eng/92-faculty/389-vasin-suttichaya"> Vasin Suttichaya</a>,
              <a href="https://www.linkedin.com/in/teepakorn-tosawadi-550453243/"> Teepakorn Tosawadi</a>,
              <a href="https://th.linkedin.com/in/ek-thamwiwatthana-aa415335"> Ek Thamwiwatthana</a>
              <br>
              <em>ICIEA, 2023</em>
              <br>
              <p>
                This method aims to monitor hot work activity and implement the risk assessment policy, which could control by the hazard area control.
                Our papar was the first work which applied the combination of object detection and perspective transformation
                with the actual hot work control measures.
              </p>
            </td>
          </tr>


          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/paper3.png" alt="" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9960268">
                <papertitle>Real-time Multiple Analog Gauges Reader for an Autonomous Robot Application</papertitle>
              </a>
              <br>
              <a href="https://th.linkedin.com/in/visarut-tripatanaphan"> Visarut Trairattanapa</a>,
              <a href="https://th.linkedin.com/in/sasin-phimsiri-a594611bb"> Sasin Phimsiri</a>,
              <strong> Chaitat Utintu</strong>,
              <a href="https://www.linkedin.com/in/riu-cherdchusakulchai-191678200/"> Riu Cherdchusakulcha</a>,
              <a href="https://www.linkedin.com/in/teepakorn-tosawadi-550453243/"> Teepakorn Tosawadi</a>,
              <a href="https://th.linkedin.com/in/ek-thamwiwatthana-aa415335"> Ek Thamwiwatthana</a>,
              <a href="https://th.linkedin.com/in/suchat-tungjitnob"> Suchat Tungjitnob</a>,
              <a href="https://th.linkedin.com/in/peemapol-tangamonsiri-16aba2200"> Peemapol Tangamonsiri</a>,
              <a href="https://th.linkedin.com/in/aphisit-takutruea-17667b160"> Aphisit Takutruea</a>,
              <a href="https://th.linkedin.com/in/apirat-khiewmeesuan-670a55214"> Apirat Khiewmeesuan</a>,
              <a href="https://th.linkedin.com/in/tanapoom-jitnaknan-2334b5224"> Tanapoom Jitnaknan</a>,
              <a href="https://www.eg.mahidol.ac.th/egmu_eng/92-faculty/389-vasin-suttichaya"> Vasin Suttichaya</a>
              <br>
              <em>iSAI-NLP, 2022</em>
              <br>
              <p>
                The methods for reading multiple analog gauges automatically using a camera. 
                The processing pipeline consists of two main stages: 1. gauge detector for extracting individual gauges and 2. gauge reader for estimating gauge values.
                For the second stage, the comparison between traditional CV and deep learning method (including CNN vs Transformer) was proposed.
              </p>
            </td>
          </tr>


          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()"   bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/paper2.png" alt="" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9795616">
                <papertitle>6D Valves Pose Estimation based on YOLACT and DenseFusion for the Offshore Robot Application</papertitle>
              </a>
              <br>
             <strong>Chaitat Utintu</strong>,
             <a href="kanut.dev"> Kanut Thammaruksa</a>, 
             <a href="https://th.linkedin.com/in/prakarn-jaroonsorn-a363441b3"> Prakarn Jaroonsorn</a>, 
             <a href="https://th.linkedin.com/in/sirawat-soksawatmakin-720587158"> Sirawat Soksawatmakin</a>, 
             <a href="https://www.linkedin.com/in/natthasit-wongsirikul-8b9b9664/"> Natthasit Wongsirikul</a>, 
             <a href="https://www.ee.ku.ac.th/www/?p=1835"> Kanjanapan Sukvichai</a>
              <br>
              <em>ECTI-CON, 2022</em>
              <br>

              <p>
                The YOLACT was exploited as an instance segmentation method to precisely extract the valves from the background then pass the segmented valve pixel to the 6D pose estimation algorithm. 
                The 2D pixels and 3D points generated are then utilized by the DenseFusion algorithm to predict the valves 6D pose composed of position and orientation based on fusion of RGB and depth features.
              </p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/journal.png" alt="" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2304.09102">
                <papertitle>An Alternative Approach for Thai Automatic Speech Recognition Based on the CNN-based Keyword Spotting with Real-World Application</papertitle>
              </a>
              <br>
              <a href="https://www.ee.ku.ac.th/www/?p=1835"> Kanjanapan Sukvichai</a>,
              <strong>Chaitat Utintu</strong>
              <br>
              <em>ASTES Journal (Q3), 2021</em>
              <br>
              <p>
                The Extended version of the paper "Automatic Speech Recognition for Thai Sentence based on MFCC and CNNs"
              </p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()"   bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/paper1.png" alt="" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9358451">
                <papertitle>Automatic Speech Recognition for Thai Sentence based on MFCC and CNNs</papertitle>
              </a>
              <br>
              <a href="https://www.ee.ku.ac.th/www/?p=1835"> Kanjanapan Sukvichai</a>, 
             <strong>Chaitat Utintu</strong>,
              <a href="https://www.linkedin.com/in/warayut-muknumporn/?trk=public_profile_browsemap&originalSubdomain=uk">
                Warayut Muknumporn</a>
              <br>
              <em>ICA-SYMP, 2021</em>
              <br>

              <p>
                Simple ASR system implemented by treating MFCC features as the image input for CNN-based object detection.
                The airport service scenario is explored in this research in order to obtain the performance of the proposed system.
              </p>
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
